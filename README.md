<h1 align="center">Liquid AI Cookbook</h1>
<p align="center"><em>Build with LFM2 Models and the LEAP SDK</em></p>

<p align="center">
    üåä <a href="https://leap.liquid.ai/docs"><b>Documentation</b></a>&nbsp&nbsp | &nbsp&nbspü§ó <a href="https://huggingface.co/LiquidAI">Hugging Face</a>&nbsp&nbsp | &nbsp&nbspüöÄ <a href="https://leap.liquid.ai">LEAP Edge SDK</a>&nbsp&nbsp | &nbsp&nbspüìö <a href="#end-2-end-tutorials">Tutorials</a>&nbsp&nbsp | &nbsp&nbspüèóÔ∏è <a href="#examples-built-by-our-community">Community Examples</a>
</p>
<p align="center">
    <a href="https://discord.gg/DFU3WQeaYD"><img src="https://img.shields.io/discord/1385439864920739850?color=7289da&label=Join%20Discord&logo=discord&logoColor=white" alt="Join Discord"></a>&nbsp&nbsp</a>
</p>


## Welcome dear developer! üëã

This repository contains **examples**, **tutorials**, and **applications** built with Liquid AI open-weight models and the open-source LEAP SDK.

Whether you're looking to customize models, deploy to laptops, edge devices, or build complete applications, you'll find resources here to get started.

## What are you looking for? üîç

- [Local agentic workflow examples](#local-agentic-workflow-examples)
- [Fine tune an LFM2 model](#fine-tune-an-lfm2-model)
- [Deploy an LFM2 model to an iOS or Android device](#deploy-to-an-edge-device)
- [End-to-end tutorials](#end-2-end-tutorials). Complete walkthroughs from setup to production.
- [Apps built by our community](#examples-built-by-our-community) that you can run and modify

## Local agentic workflow examples ü§ñ

| Name | What's that? |  |
|-------|-----------|---------------|
| **invoice-parser** | A Python CLI that extracts structured data from bill pictures using a 2-step agentic workflow | [‚ñ∂Ô∏è Go to the code](./examples/invoice-parser/) |
| **audio-transcription-cli** | A Python CLI for real-time audio-to-text transcription using LFM2-Audio-1.5B with llama.cpp | [‚ñ∂Ô∏è Go to the code](./examples/audio-transcription-cli/) |



## Fine-Tune an LFM2 model üéØ

### LFM2 (Text-to-text)

LFM2 is a generation of hybrid models, designed for on-device deployment, ranging from 350M up to 8B parameters.

These models are particularly suited for agentic tasks, data extraction, RAG, creative writing, and multi-turn conversations. We do not recommend using them for tasks that are knowledge-intensive or require programming skills.

<!-- #### Liquid Nanos for Text-to-Text problems -->

| Model | Technique |  |
|-------|-----------|---------------|
| [LFM2-8B-A1B](https://huggingface.co/LiquidAI/LFM2-8B-A1B) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1OXLEuSmzF4AjJ7yqRCDTn-ltvFjoGR9j?usp=sharing) |
|  | Direct Preference Optimization (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Q8hIHIQ8oofshcNYHUcYp1akUcZ-ufSn?usp=sharing) |
||||
| [LFM2-2.6B](https://huggingface.co/LiquidAI/LFM2-2.6B) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j5Hk_SyBb2soUsuhU0eIEA9GwLNRnElF?usp=sharing) |
|  | Supervised Fine Tuning (Axolotl) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/155lr5-uYsOJmZfO6_QZPjbs8hA_v8S7t?usp=sharing) |
|  | Supervised Fine Tuning (Unsloth) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HROdGaPFt1tATniBcos11-doVaH7kOI3?usp=sharing) |
|  | Direct Preference Optimization (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MQdsPxFHeZweGsNx4RH7Ia8lG8PiGE1t?usp=sharing) |
||||
| [LFM2-1.2B](https://huggingface.co/LiquidAI/LFM2-1.2B) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j5Hk_SyBb2soUsuhU0eIEA9GwLNRnElF?usp=sharing) |
|  | Supervised Fine Tuning (Axolotl) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/155lr5-uYsOJmZfO6_QZPjbs8hA_v8S7t?usp=sharing) |
|  | Supervised Fine Tuning (Unsloth) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HROdGaPFt1tATniBcos11-doVaH7kOI3?usp=sharing) |
|  | Direct Preference Optimization (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MQdsPxFHeZweGsNx4RH7Ia8lG8PiGE1t?usp=sharing) |
||||
| [LFM2-700M](https://huggingface.co/LiquidAI/LFM2-700M) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j5Hk_SyBb2soUsuhU0eIEA9GwLNRnElF?usp=sharing) |
|  |Supervised Fine Tuning (Axolotl) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/155lr5-uYsOJmZfO6_QZPjbs8hA_v8S7t?usp=sharing) |
|  |Supervised Fine Tuning (Unsloth) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HROdGaPFt1tATniBcos11-doVaH7kOI3?usp=sharing) |
| | Direct Preference Optimization (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MQdsPxFHeZweGsNx4RH7Ia8lG8PiGE1t?usp=sharing) |
||||
| [LFM2-350M](https://huggingface.co/LiquidAI/LFM2-350M) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j5Hk_SyBb2soUsuhU0eIEA9GwLNRnElF?usp=sharing) |
|  |Supervised Fine Tuning (Axolotl) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/155lr5-uYsOJmZfO6_QZPjbs8hA_v8S7t?usp=sharing) |
|  |Supervised Fine Tuning (Unsloth) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HROdGaPFt1tATniBcos11-doVaH7kOI3?usp=sharing) |
| | Direct Preference Optimization (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1MQdsPxFHeZweGsNx4RH7Ia8lG8PiGE1t?usp=sharing) |

Need a model for data extraction, RAG, tool use, or math reasoning? Start with our Nano checkpoints‚Äîthey're already specialized for these tasks.

| Model | Use Cases |
|-------|-----------|
| ‚Ä¢  [LFM2-1.2B-Extract](https://huggingface.co/LiquidAI/LFM2-1.2B-Extract)<br> ‚Ä¢ [LFM2-350M-Extract](https://huggingface.co/LiquidAI/LFM2-350M-Extract) | ‚Ä¢ Extracting invoice details from emails into structured JSON<br>‚Ä¢ Converting regulatory filings into XML for compliance systems<br>‚Ä¢ Transforming customer support tickets into YAML for analytics pipelines<br>‚Ä¢ Populating knowledge graphs with entities and attributes from unstructured reports |
| [LFM2-1.2B-RAG](https://huggingface.co/LiquidAI/LFM2-1.2B-RAG) | ‚Ä¢ Chatbot to ask questions about the documentation of a particular product.<br> ‚Ä¢ Custom support with an internal knowledge base to provide grounded answers. <br> ‚Ä¢ Academic research assistant with multi-turn conversations about research papers and course materials.|
| [LFM2-1.2B-Tool](https://huggingface.co/LiquidAI/LFM2-1.2B-Tool)| ‚Ä¢ Mobile and edge devices requiring instant API calls, database queries, or system integrations without cloud dependency.<br> ‚Ä¢ Real-time assistants in cars, IoT devices, or customer support, where response latency is critical. <br> ‚Ä¢ Resource-constrained environments like embedded systems or battery-powered devices needing efficient tool execution.|
| [LFM2‚Äë350M‚ÄëMath](https://huggingface.co/LiquidAI/LFM2-350M-Math)| ‚Ä¢ Mathematical problem solving.<br> ‚Ä¢ Reasoning tasks.|

> [!NOTE]
>
> The supported languages for these models are: English, Arabic, Chinese, French, German, Japanese, Korean, Portuguese, and Spanish.
> 
> **Need support for another language?**
> 
> [Join the Liquid AI Discord Community](https://discord.gg/DFU3WQeaYD) and request it! Our community is working on expanding language support, and your input helps us prioritize which languages to tackle next. Connect with fellow developers, share your use cases, and collaborate on multilingual AI solutions.
> 
> [![Join Discord](https://img.shields.io/discord/1385439864920739850?color=7289da&label=Join%20Discord&logo=discord&logoColor=white)](https://discord.gg/DFU3WQeaYD)

### LFM2-VL (Text+Image to Text)

LFM2-VL is our first series of vision-language models, designed for on-device deployment.

| Model | Technique |  |
|-------|-----------|---------------|
| [LFM2-VL-1.6B](https://huggingface.co/LiquidAI/LFM2-VL-1.6B) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1csXCLwJx7wI7aruudBp6ZIcnqfv8EMYN?usp=sharing) |
| [LFM2-VL-450M](https://huggingface.co/LiquidAI/LFM2-VL-450M) | Supervised Fine Tuning (TRL) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1csXCLwJx7wI7aruudBp6ZIcnqfv8EMYN?usp=sharing) |


## Deploy to an edge device üì±

The [LEAP Edge SDK](https://leap.liquid.ai/docs/edge-sdk/overview) is our native framework for running LFM2 models on mobile devices.

Written for Android (Kotlin) and iOS (Swift), the goal of the Edge SDK is to make Small Language Model deployment as easy as calling a cloud LLM API endpoint, for any app developer.

| Platform | Example |  |
|-------|-----------|---------------|
| **Android** | LeapChat: A comprehensive chat application with real-time token streaming, persistent message history, and modern chat UI featuring message bubbles and typing indicators | [ü§ñ Tutorial](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/Android/LeapChat) |
|  | SloganApp: Single turn generation for marketing. The UI is implemented with Android Views.| [ü§ñ Tutorial](./examples/leap-slogan-example-ios/README.md) |
|  | ShareAI: Website summary generator | [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/Android/ShareAI) |
|  | Recipe Generator: Structured output generation with the LEAP SDK | [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/Android/RecipeGenerator) |
|  | Visual Language Model example | [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/Android/VLMExample) |
||||
| **iOS** | LeapChat: A comprehensive chat application demonstrating advanced LeapSDK features including real-time streaming, conversation management, and modern UI components. | [‚ñ∂Ô∏è Go to the code ](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/iOS/LeapChatExample) |
|  | LeapSloganExample: A simple SwiftUI app demonstrating basic LeapSDK integration for text generation.| [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/iOS/LeapChatExample) |
|  | Recipe Generator: Structured output generation | [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/iOS/RecipeGenerator) |
|  | Audio demo: A SwiftUI app demonstrating audio input and output with the LeapSDK for on-device AI inference. | [‚ñ∂Ô∏è Go to the code](https://github.com/Liquid4All/LeapSDK-Examples/tree/main/iOS/LeapAudioDemo) |



## End-2-end Tutorials üìö

Complete end-to-end tutorials that take you from setup to deployment.

| Tutorial | Repository |
|----------|------------|
| Super fast and accurate image classification on edge devices | [‚ñ∂Ô∏è Go to the repo](https://github.com/Paulescu/image-classification-with-local-vlms) ![GitHub Repo stars](https://img.shields.io/github/stars/Paulescu/image-classification-with-local-vlms) |
| Let's build a Chess game using small and local Large Language Models | [‚ñ∂Ô∏è Go to the repo](https://github.com/Paulescu/chess-game) ![GitHub Repo stars](https://img.shields.io/github/stars/Paulescu/chess-game) |


## Examples built by our community üåü

Working applications that demonstrate Liquid models in action.

| Project | Repository |
|---------|------------|
| TranslatorLens: Building An Offline Translation Camera | [‚ñ∂Ô∏è Go to the repo](https://github.com/linmx0130/TranslatorLens) ![GitHub Repo stars](https://img.shields.io/github/stars/linmx0130/TranslatorLens) |
| Food Images Fine-tuning | [‚ñ∂Ô∏è Go to the repo](https://github.com/benitomartin/food-images-finetuning) ![GitHub Repo stars](https://img.shields.io/github/stars/benitomartin/food-images-finetuning) |



<!-- Detailed documentation for working with Liquid models:

- [Model API](docs/api/models.md) - Load, configure, and run models
- [Training API](docs/api/training.md) - Fine-tuning and training utilities
- [Deployment API](docs/api/deployment.md) - Optimization and export tools
- [Data Processing](docs/api/data.md) - Dataset handling and preprocessing -->


## Contributing ü§ù

We welcome contributions!

- Open a PR with a link to your project github repo in the `Examples built by our community` section.


## Support üí¨

- üìñ [Liquid AI Documentation](https://leap.liquid.ai/docs)
- üí¨ [Join our community on Discord](https://discord.gg/DFU3WQeaYD)